<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Jiahao Li</title>
  
  <meta name="author" content="Jiahao Li">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="images/icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Jiahao Li</name>
              </p>
              <p>I am a PhD student at <a href="https://www.ttic.edu/">TTI-Chicago</a> advised by <a href="https://home.ttic.edu/~gregory/">Greg Shakhnarovich</a> in the <a href="https://pals.ttic.edu/">PALS</a> Lab. I primarily work on 3D computer vision and generative modelling. 
              </p>
              <p>Before coming to TTIC, I received my Master of Computer Science from <a href="https://cse.wustl.edu/index.html">Washington University in St. Louis</a>, advised by <a href="https://projects.ayanc.org/">Ayan Chakrabarti</a>. I got my Bachelor of Mathematics from <a href="https://www.sysu.edu.cn/sysuen/">Sun Yat-sen University</a>. I have interned at <a href="https://tech.facebook.com/reality-labs/">Meta Reality Labs</a> and <a href="https://en.megvii.com/">Megvii</a>.
              </p>
              <!-- <p> -->
              <!--   At Google I've worked on <a href="https://www.google.com/glass/start/">Glass</a>,  <a href="https://ai.googleblog.com/2014/04/lens-blur-in-new-google-camera-app.html">Lens Blur</a>, <a href="https://ai.googleblog.com/2014/10/hdr-low-light-and-high-dynamic-range.html">HDR+</a>, <a href="https://blog.google/products/google-ar-vr/introducing-next-generation-jump/">Jump</a>, <a href="https://ai.googleblog.com/2017/10/portrait-mode-on-pixel-2-and-pixel-2-xl.html">Portrait Mode</a>, <a href="https://ai.googleblog.com/2020/12/portrait-light-enhancing-portrait.html">Portrait Light</a>, and <a href="https://www.matthewtancik.com/nerf">NeRF</a>. I did my PhD at <a href="http://www.eecs.berkeley.edu/">UC Berkeley</a>, where I was advised by <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a> and funded by the <a href="http://www.nsfgrfp.org/">NSF GRFP</a>. I've received the <a href="https://www2.eecs.berkeley.edu/Students/Awards/15/">C.V. Ramamoorthy Distinguished Research Award</a> and the <a href="https://www.thecvf.com/?page_id=413#YRA">PAMI Young Researcher Award</a>. -->
              <!-- </p> -->
              <p style="text-align:center">
                <a href="mailto:jiahao@ttic.edu">Email</a> &nbsp/&nbsp
                <!-- <a href="data/JonBarron-CV.pdf">CV</a> &nbsp/&nbsp -->
                <!-- <a href="data/JonBarron-bio.txt">Bio</a> &nbsp/&nbsp -->
                <a href="https://scholar.google.com/citations?user=w9jtLkIAAAAJ">Google Scholar</a> &nbsp/&nbsp
                <!-- <a href="https://twitter.com/jon_barron">Twitter</a> &nbsp/&nbsp -->
                <a href="https://github.com/jiahaoli95">Github</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/jiahaoli95/">LinkedIn</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/avatar.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/avatar.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody> -->
        <!--     <tr> -->
        <!--     <td style="padding:20px;width:100%;vertical-align:middle"> -->
        <!--       <heading>Research</heading> -->
        <!--       <p> -->
        <!--         I'm interested in computer vision, machine learning, optimization, and image processing. Much of my research is about inferring the physical world (shape, motion, color, light, etc) from images. Representative papers are <span class="highlight">highlighted</span>. -->
        <!--       </p> -->
        <!--     </td> -->
        <!--   </tr> -->
        <!-- </tbody></table> -->
        <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody> -->
				
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
				
		  
          <tr onmouseout="nerf_stop()" onmouseover="nerf_start()"  bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nerf_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/vase_small.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/vase_still.png' width="160">
              </div>
              <script type="text/javascript">
                function nerf_start() {
                  document.getElementById('nerf_image').style.opacity = "1";
                }

                function nerf_stop() {
                  document.getElementById('nerf_image').style.opacity = "0";
                }
                nerf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://www.matthewtancik.com/nerf">
                <papertitle>NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis</papertitle>
              </a>
              <br>
              <a href="https://bmild.github.io/">Ben Mildenhall*</a>,
              <a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan*</a>,
              <a href="http://matthewtancik.com/">Matthew Tancik*</a>, <br>
              <strong>Jonathan T. Barron</strong>,
              <a href="http://cseweb.ucsd.edu/~ravir/">Ravi Ramamoorthi</a>,
              <a href="https://www2.eecs.berkeley.edu/Faculty/Homepages/yirenng.html">Ren Ng</a>
              <br>
              <em>ECCV</em>, 2020 &nbsp <font color="red"><strong>(Oral Presentation, Best Paper Honorable Mention, CACM Research Highlight)</strong></font>
              <br>
              <a href="http://www.matthewtancik.com/nerf">project page</a>
              /
              <a href="https://arxiv.org/abs/2003.08934">arXiv</a>
              /
              <a href="https://www.youtube.com/watch?v=LRAqeM8EjOo&t">talk video</a>
              /
              <a href="https://www.youtube.com/watch?v=JuH79E8rdKc">supp video</a>
              /
              <a href="https://github.com/bmild/nerf">code</a>
              /
              <a href="https://cacm.acm.org/magazines/2022/1/257450-nerf/fulltext">CACM</a> <a href="https://cacm.acm.org/magazines/2022/1/257453-technical-perspective-neural-radiance-fields-explode-on-the-scene/fulltext">(foreward)</a>
              <p></p>
              <p>
              Training a tiny non-convolutional neural network to reproduce a scene using volume rendering achieves photorealistic view synthesis.</p>
            </td>
          </tr> 


          <tr onmouseout="adaptclip_stop()" onmouseover="adaptclip_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='adaptclip_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/adaptclip_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/adaptclip_before.jpg' width="160">
              </div>
              <script type="text/javascript">
                function adaptclip_start() {
                  document.getElementById('adaptclip_image').style.opacity = "1";
                }

                function adaptclip_stop() {
                  document.getElementById('adaptclip_image').style.opacity = "0";
                }
                adaptclip_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://arxiv.org/abs/2204.03647">
                <papertitle>Adapting CLIP For Phrase Localization Without Further Training</papertitle>
              </a>
              <br>
              <strong>Jiahao Li</strong>,
              <a href="https://home.ttic.edu/~gregory/">Greg Shakhnarovich</a>,
              <a href="https://raymond-yeh.com/">Raymond A. Yeh</a>
              <br>
              <a href="https://arxiv.org/abs/2204.03647">arXiv</a>
              <p></p>
              <p>We do phrase localization by exploiting the ViT architecture of CLIP without extra training.</p>
            </td>
          </tr>
					
    
          <tr onmouseout="idam_stop()" onmouseover="idam_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='idam_image_before'>
                  <img src='images/idam_before.png' width="160">
                </div>
                <div class="two" id='idam_image_after'>
                  <img src='images/idam_after.png' width="160">
                </div>
              </div>
              <script type="text/javascript">
                function idam_start() {
                  document.getElementById('idam_image_before').style.opacity = "0";
                  document.getElementById('idam_image_after').style.opacity = "1";
                }

                function idam_stop() {
                  document.getElementById('idam_image_before').style.opacity = "1";
                  document.getElementById('idam_image_after').style.opacity = "0";
                }
                idam_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1910.10328">
                <papertitle>Iterative Distance-Aware Similarity Matrix Convolution with Mutual-Supervised Point Elimination for Efficient Point Cloud Registration</papertitle>
              </a>
              <br>
              <strong>Jiahao Li</strong>,
              Changhao Zhang, 
              Ziyao Xu,
              Hangning Zhou,
              Chi Zhang
              <br>
              <em>ECCV</em>, 2020
              <br>
              <a href="https://arxiv.org/abs/1910.10328">arXiv</a>
              <p></p>
              <p>
              A deep learning based point cloud registration pipeline.
              </p>
            </td>
          </tr>


        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:middle;font-size:small;">
                Website template stolen from <a href="https://github.com/jonbarron/jonbarron_website">here</a>.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
